{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "from datetime import datetime\n",
    "\n",
    "CHECKS = pd.read_json('../src/checks.json')\n",
    "DROPS = pd.read_json('../src/drops.json')\n",
    "EVENTS = pd.read_json('../src/events.json')\n",
    "ITEMS = pd.read_json('../src/items.json')\n",
    "TILES = pd.read_json('../src/tiles.json')\n",
    "\n",
    "ITEM_IDS = {\n",
    "    'sword': 27,\n",
    "    'hammer': 13,\n",
    "    'lantern': 12,\n",
    "    'firerod': 7,\n",
    "    'icerod': 8,\n",
    "    'boots': 23,\n",
    "    'glove': 24,\n",
    "    'mirror': 22,\n",
    "    'bow': 0,\n",
    "    'hookshot': 4,\n",
    "    'byrna': 21,\n",
    "    'cape': 52,\n",
    "    'pearl': 26,\n",
    "    'bombos': 9,\n",
    "    'flippers': 25,\n",
    "}\n",
    "\n",
    "# Value that will return false for all relevant checks\n",
    "ITEM_NEVER_FOUND = 100_000_000\n",
    "\n",
    "RUN_START = 20_000\n",
    "RUN_END = 20_001\n",
    "\n",
    "TILE_MASK = 0\n",
    "LOCATION_MASK = 1000\n",
    "EVENT_MASK = 2000\n",
    "\n",
    "def item_log_idx(df: DataFrame, item: str, progressive_level: int = 1) -> int:\n",
    "    found_items = df[df.item_id == ITEM_IDS[item]].index\n",
    "    return found_items[progressive_level-1] if len(found_items) >= progressive_level else ITEM_NEVER_FOUND\n",
    "\n",
    "def item_log_idx(df: DataFrame, item: str, progressive_level: int = 1) -> int:\n",
    "    found_items = df[df.item_id == ITEM_IDS[item]].index\n",
    "    return (\n",
    "        found_items[progressive_level - 1]\n",
    "        if len(found_items) >= progressive_level\n",
    "        else ITEM_NEVER_FOUND\n",
    "    )\n",
    "\n",
    "def can_slash(df: DataFrame) -> DataFrame:\n",
    "    df['can_slash'] = df.index >= item_log_idx(df, 'sword')\n",
    "    return df\n",
    "\n",
    "def can_hammer_things(df: DataFrame) -> DataFrame:\n",
    "    df['can_hammer'] = df.index >= item_log_idx(df, 'hammer')\n",
    "    return df\n",
    "\n",
    "def can_dash(df: DataFrame) -> DataFrame:\n",
    "    df['can_dash'] = df.index >= item_log_idx(df, 'boots')\n",
    "    return df\n",
    "\n",
    "def can_shoot(df: DataFrame) -> DataFrame:\n",
    "    df['can_shoot'] = df.index >= item_log_idx(df, 'bow')\n",
    "    return df\n",
    "\n",
    "def can_lift_rocks(df: DataFrame) -> DataFrame:\n",
    "    df['can_lift_rocks'] = df.index >= item_log_idx(df, 'glove')\n",
    "    return df\n",
    "\n",
    "def can_lift_heavy_rocks(df: DataFrame) -> DataFrame:\n",
    "    df['can_lift_heavy_rocks'] = df.index >= item_log_idx(df, 'glove', 2)\n",
    "    return df\n",
    "\n",
    "def can_remain_link_in_dw(df: DataFrame) -> DataFrame:\n",
    "    df['can_remain_link_in_dw'] = df.index >= item_log_idx(df, 'pearl')\n",
    "    return df\n",
    "\n",
    "def can_burn_things(df: DataFrame) -> DataFrame:\n",
    "    df['can_burn_things'] = df.index >= item_log_idx(df, 'firerod')\n",
    "    return df\n",
    "\n",
    "def can_melt_things(df: DataFrame) -> DataFrame:\n",
    "    can_melt_idx = min(item_log_idx(df, 'firerod'), item_log_idx(df, 'bombos'))\n",
    "    df['can_melt_things'] = df.index >= can_melt_idx\n",
    "    return df\n",
    "\n",
    "def can_light_things(df: DataFrame) -> DataFrame:\n",
    "    can_light_idx = min(item_log_idx(df, 'firerod'), item_log_idx(df, 'lantern'))\n",
    "    df['can_light_things'] = df.index >= can_light_idx\n",
    "    return df\n",
    "\n",
    "def can_traverse_big_gaps(df: DataFrame) -> DataFrame:\n",
    "    df['can_traverse_big_gaps'] = df.index >= item_log_idx(df, 'hookshot')\n",
    "    return df\n",
    "\n",
    "def can_swim(df: DataFrame) -> DataFrame:\n",
    "    df['can_swim'] = df.index >= item_log_idx(df, 'flippers')\n",
    "    return df\n",
    "\n",
    "def can_pass_energy_barriers(df: DataFrame) -> DataFrame:\n",
    "    can_pass_idx = min(item_log_idx(df, 'sword', progressive_level=2), item_log_idx(df, 'byrna'), item_log_idx(df, 'cape'))\n",
    "    df['can_pass_energy_barriers'] = df.index >= can_pass_idx\n",
    "    return df\n",
    "\n",
    "def create_row_hash(row):\n",
    "    key_tuple = tuple((val for _, val in sorted(row.items(), key=lambda kv: kv[0])))\n",
    "    return hash(key_tuple)\n",
    "\n",
    "def apply_current_abilities(df: DataFrame) -> DataFrame:\n",
    "    df = can_slash(df)\n",
    "#    df = can_hammer_things(df)\n",
    "    df = can_dash(df)\n",
    "#    df = can_shoot(df)\n",
    "    df = can_lift_rocks(df)\n",
    "#    df = can_lift_heavy_rocks(df)\n",
    "    df = can_remain_link_in_dw(df)\n",
    "#    df = can_burn_things(df)\n",
    "#    df = can_melt_things(df)\n",
    "#    df = can_light_things(df)\n",
    "    df = can_traverse_big_gaps(df)\n",
    "#    df = can_swim(df)\n",
    "    ability_columns = [c for c in df.columns if c.startswith('can_')]\n",
    "    df['ability_hash'] = df[ability_columns].apply(create_row_hash, axis=1)\n",
    "    # df = df.drop(columns=ability_columns)\n",
    "\n",
    "    return df\n",
    "\n",
    "def only_movements(df: DataFrame) -> DataFrame:\n",
    "    df['movement_id'] = np.nan\n",
    "    df.loc[df.tile_id.notna(), 'movement_id'] = df.loc[df.tile_id.notna(), 'tile_id'] + TILE_MASK\n",
    "    df.loc[df.location_id.notna(), 'movement_id'] = df.loc[df.location_id.notna(), 'location_id'] + LOCATION_MASK\n",
    "    df.loc[df.event_id.notna(), 'movement_id'] = df.loc[df.event_id.notna(), 'event_id'] + EVENT_MASK\n",
    "\n",
    "    return df[df.movement_id.notna()].drop(columns=['item_id', 'event_id', 'location_id', 'tile_id'])\n",
    "\n",
    "def add_previous_and_next_move(df: DataFrame) -> DataFrame:\n",
    "    '''Used to create a `route_hash`'''\n",
    "    df['preprevious_move'] = df.movement_id.shift(2, fill_value=RUN_START)\n",
    "    df['previous_move'] = df.movement_id.shift(1, fill_value=RUN_START)\n",
    "    df['next_move'] = df.movement_id.shift(-1, fill_value=RUN_END)\n",
    "    df['nextnext_move'] = df.movement_id.shift(-2, fill_value=RUN_END)\n",
    "    return df\n",
    "\n",
    "def apply_routes(df: DataFrame) -> DataFrame:\n",
    "    df = add_previous_and_next_move(df)\n",
    "    move_columns = [c for c in df.columns if 'move' in c]\n",
    "    df['route_id'] = df[move_columns].apply(create_row_hash, axis=1)\n",
    "    return df\n",
    "\n",
    "def add_time_deltas(df: DataFrame) -> DataFrame:\n",
    "    start_time = df['timestamp'].min()\n",
    "    df['timestamp'] = df['timestamp'] - start_time\n",
    "    df['time_delta'] = df['timestamp'] - df['timestamp'].shift(1, fill_value=0)\n",
    "    return df\n",
    "\n",
    "def apply_route_ability_hash(df: DataFrame) -> DataFrame:\n",
    "    if not 'ability_hash' in df.columns:\n",
    "        df = apply_current_abilities(df)\n",
    "    if not 'route_id' in df.columns:\n",
    "        df = only_movements(df)\n",
    "        df = apply_routes(df)\n",
    "    df['route_ability_id'] = df[['route_id', 'ability_hash']].apply(create_row_hash, axis=1)\n",
    "    return df\n",
    "\n",
    "def convert_legacy_csv(df: DataFrame) -> DataFrame:\n",
    "    if \"transition_id\" in df.columns:\n",
    "        df[\"tile_id\"] = df[\"transition_id\"]\n",
    "        df = df.drop(columns=[\"transition_id\"])\n",
    "    return df\n",
    "\n",
    "def read_runs(glob_path: str):\n",
    "    dfs: List[DataFrame] = []\n",
    "    for path in Path.cwd().glob(glob_path):\n",
    "        df = pd.read_csv(path)\n",
    "        df = convert_legacy_csv(df)\n",
    "        df = apply_route_ability_hash(df)\n",
    "        df = add_time_deltas(df)\n",
    "        df['filename'] = path.name\n",
    "        dfs.append(df)\n",
    "    return pd.concat(dfs)\n",
    "\n",
    "def best_route_time(runs):\n",
    "    def wrapped(row):\n",
    "        return runs[runs.route_ability_id == row.route_ability_id].time_delta.min()\n",
    "    return wrapped\n",
    "\n",
    "class RunComparator:\n",
    "    def __init__(self, all_runs: DataFrame) -> None:\n",
    "        self.all_runs: DataFrame = all_runs\n",
    "        self.best_route_time = best_route_time(self.all_runs)\n",
    "\n",
    "    def apply_best_route_time(self, selected_run):\n",
    "        rows = []\n",
    "        for _, row in selected_run.iterrows():\n",
    "            row[\"best_time_delta\"] = self.best_route_time(row)\n",
    "            row['deltadelta'] = row['time_delta'] - row['best_time_delta']\n",
    "            row['deltapercent'] = round((row['time_delta']/row['best_time_delta'] - 1)*100,0) if row['best_time_delta'] > 0 else 0\n",
    "            rows.append(row)\n",
    "        return DataFrame.from_records(rows)\n",
    "\n",
    "    def translate_ids(self, selected_run):\n",
    "        rows = []\n",
    "        move_col_names = ['-2', '-1', '0', '+1', '+2']\n",
    "        for _, row in selected_run.iterrows():\n",
    "            moves = []\n",
    "            move_ids = [row['preprevious_move'], row['previous_move'], row['movement_id'], row['next_move'], row['nextnext_move']]\n",
    "            for move_id in move_ids:\n",
    "                if move_id >= 2000:\n",
    "                    moves.append(EVENTS.loc[EVENTS.id == move_id - 2000, 'name'])\n",
    "                elif move_id >= 1000:\n",
    "                    moves.append(CHECKS.loc[CHECKS.id == move_id - 1000, 'name'])\n",
    "                else:\n",
    "                    moves.append(TILES.loc[TILES.id == move_id - 0, 'name'])\n",
    "            for move,name in zip(moves, move_col_names):\n",
    "                row[name] = move\n",
    "            rows.append(row)\n",
    "        return DataFrame.from_records(rows)\n",
    "\n",
    "    def best_possible_time_for(self, filename: str) -> DataFrame:\n",
    "        selected_run = self.all_runs[self.all_runs.filename == filename]\n",
    "        if len(selected_run) == 0:\n",
    "            raise AttributeError(\n",
    "                f\"run {filename} does not exist. Possible values: {self.all_runs['filename'].unique()}\"\n",
    "            )\n",
    "        else:\n",
    "            processed = self.apply_best_route_time(selected_run)\n",
    "            processed = self.translate_ids(selected_run)\n",
    "            print(\"Run: \", filename)\n",
    "            print(\n",
    "                f\"Total time: {datetime.fromtimestamp(processed.time_delta.sum()/ 1000) - datetime.fromtimestamp(0)}\"\n",
    "            )\n",
    "            print(\n",
    "                f\"Best possible time: {datetime.fromtimestamp(processed.best_time_delta.sum()/1000) - datetime.fromtimestamp(0)}\\n\"\n",
    "            )\n",
    "            return processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run:  Ludicrous Speed - 20211213 - Mike - 204029.csv\n",
      "Total time: 1:06:55.964000\n",
      "Best possible time: 1:04:11.329000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compare = RunComparator(read_runs('../RUNS/*.csv'))\n",
    "run = compare.best_possible_time_for('Ludicrous Speed - 20211213 - Mike - 204029.csv')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eea02655494ccfca9b943908b44a342bce2b5b6ec71a404df79d1eaeac6a6912"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
